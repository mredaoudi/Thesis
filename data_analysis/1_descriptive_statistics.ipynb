{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df700cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re\n",
    "import json\n",
    "import emoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from nltk.tokenize.casual import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract json into dictionary\n",
    "def load_json_data(dataset_name):\n",
    "    return json.load(open('../data/' + dataset_name + '.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment labels of tweets by ID (training dataset only)\n",
    "def sentiment_labels():\n",
    "    dataset = load_json_data('training')\n",
    "    tweet_ids = []\n",
    "    labels = []\n",
    "    \n",
    "    for tweet, details in dataset.items():\n",
    "        tweet_ids.append(tweet)\n",
    "        labels.append(details['sentiment_label'])\n",
    "    return pd.DataFrame({'Tweet ID': tweet_ids, 'Sentiment Label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e23edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to collect all tags (mentions & hashtags) of tweets in dataset\n",
    "def get_tags(dataset_name, tag_type):\n",
    "    dataset = load_json_data(dataset_name)\n",
    "    tag_identifier = 'tag' if tag_type == 'hashtags' else 'username'\n",
    "    tweet_ids = []\n",
    "    tweet_tags = []\n",
    "    \n",
    "    for tweet, details in dataset.items():\n",
    "        if (details['tweet_data'] and\n",
    "            ('entities' in details['tweet_data']) and\n",
    "            (tag_type in details['tweet_data']['entities'])):\n",
    "            for tag in details['tweet_data']['entities'][tag_type]:\n",
    "                tweet_ids.append(tweet)\n",
    "                tweet_tags.append(tag[tag_identifier])\n",
    "        else:\n",
    "            tweet_ids.append(tweet)\n",
    "            tweet_tags.append(None)\n",
    "    return pd.DataFrame({'Tweet ID': tweet_ids, tag_type.capitalize(): tweet_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect sources (devices) of tweets in dataset\n",
    "def get_sources(dataset_name):\n",
    "    dataset = load_json_data(dataset_name)\n",
    "    tweet_ids = []\n",
    "    tweet_sources = []\n",
    "    \n",
    "    for tweet, details in dataset.items():\n",
    "        tweet_ids.append(tweet)\n",
    "        tweet_sources.append(details['tweet_data']['source'] if details['tweet_data'] else None)\n",
    "    return pd.DataFrame({'Tweet ID': tweet_ids, 'Tweet Source': tweet_sources})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a8e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to see which users are verified or not\n",
    "def get_verifications(dataset_name):\n",
    "    dataset = load_json_data(dataset_name)\n",
    "    tweet_ids = []\n",
    "    users_is_verified = []\n",
    "    \n",
    "    for tweet, details in dataset.items():\n",
    "        tweet_ids.append(tweet)\n",
    "        users_is_verified.append(details['user_data']['verified'] if details['user_data'] else None)\n",
    "    return pd.DataFrame({'Tweet ID': tweet_ids, 'User Verified': users_is_verified})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate time difference between date of tweet and creation of the user account\n",
    "def calculate_time_difference(dataset_name):\n",
    "    dataset = load_json_data(dataset_name)\n",
    "    tweet_ids = []\n",
    "    time_difference = []\n",
    "    \n",
    "    for tweet, details in dataset.items():\n",
    "        tweet_ids.append(tweet)\n",
    "        if details['tweet_data']:\n",
    "            user_created_at = dt.strptime(details['user_data']['created_at'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            tweet_created_at = dt.strptime(details['tweet_data']['created_at'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            time_diff = tweet_created_at - user_created_at\n",
    "            time_difference.append(time_diff.days)\n",
    "        else:\n",
    "            time_difference.append(None)\n",
    "\n",
    "    return pd.DataFrame({'Tweet ID': tweet_ids, 'Time Difference': time_difference})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab469a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_text(dataset_name):\n",
    "    dataset = load_json_data(dataset_name)\n",
    "    tweet_ids = []\n",
    "    tweet_text = []\n",
    "    \n",
    "    for tweet, details in dataset.items():\n",
    "        tweet_ids.append(tweet)\n",
    "        tweet_text.append(details['tweet_data']['text'] if details['tweet_data'] else None)\n",
    "    return pd.DataFrame({'Tweet ID': tweet_ids, 'Tweet Text': tweet_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc33659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_count(dataset_name):\n",
    "    dataset = load_json_data(dataset_name)\n",
    "    tweet_ids = []\n",
    "    tweet_char_counter = []\n",
    "    \n",
    "    for tweet, details in dataset.items():\n",
    "        tweet_ids.append(tweet)\n",
    "        if details['tweet_data']:\n",
    "            # Remove links\n",
    "            text = re.sub(r'http\\S+', '', details['tweet_data']['text'])\n",
    "            tweet_char_counter.append(len(text))\n",
    "        else:\n",
    "            tweet_char_counter.append(np.nan)\n",
    "        \n",
    "    return pd.DataFrame({'Tweet ID': tweet_ids, 'Character Count': tweet_char_counter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emojis(dataset_name):\n",
    "    dataset = load_json_data(dataset_name)\n",
    "    tweet_ids = []\n",
    "    emojis = []\n",
    "    \n",
    "    for tweet, details in dataset.items():\n",
    "        if details['tweet_data']:\n",
    "            for char in details['tweet_data']['text']:\n",
    "                if char in emoji.UNICODE_EMOJI['fr']:\n",
    "                    tweet_ids.append(tweet)\n",
    "                    emojis.append(char)\n",
    "        \n",
    "    return pd.DataFrame({'Tweet ID': tweet_ids, 'Emoji': emojis})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2582ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sentiment_labels()\n",
    "text = tweet_text('training')\n",
    "emojis = get_emojis('training')\n",
    "sources = get_sources('training')\n",
    "char_count = character_count('training')\n",
    "hashtags = get_tags('training', 'hashtags')\n",
    "mentions = get_tags('training', 'mentions')\n",
    "verifications = get_verifications('training')\n",
    "time_differences = calculate_time_difference('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f8abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['Sentiment Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hashtags.groupby('Tweet ID').count().apply(lambda x: x >= 1).value_counts())\n",
    "print(mentions.groupby('Tweet ID').count().apply(lambda x: x >= 1).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b462d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(labels, sources, how='inner').groupby(\n",
    "    ['Sentiment Label', 'Tweet Source']\n",
    ").count().sort_values(\n",
    "    ['Sentiment Label', 'Tweet ID'], ascending=[False, False]\n",
    ").query('`Tweet ID` > 100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4d799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(labels, verifications, how='inner').groupby(\n",
    "    ['Sentiment Label', 'User Verified']\n",
    ").count().sort_values(\n",
    "    ['Sentiment Label', 'Tweet ID'], ascending=[False, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(labels, emojis, how='inner').groupby(\n",
    "    ['Sentiment Label', 'Emoji']\n",
    ").count().sort_values(\n",
    "    ['Sentiment Label', 'Tweet ID'], ascending=[False, False]\n",
    ").query('`Tweet ID` > 25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b79f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(labels, time_differences, how='inner').groupby(['Sentiment Label']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26060d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(labels, char_count, how='inner').groupby(['Sentiment Label']).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
